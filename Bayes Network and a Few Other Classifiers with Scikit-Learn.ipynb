{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bayes Networks\n",
    "\n",
    "Sometimes we get so caught up in all the latest in deep nets that we forget to look at some of the more basic approaches.  One of those is Bayes Networks.  In a nutshell, a Bayesian network [is](https://en.wikipedia.org/wiki/Bayesian_network) a \"probabilistic graphical model (a type of statistical model) that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG)\".\n",
    "\n",
    "Besides the Wikipedia article, [scikit-learn](http://scikit-learn.org/stable/modules/naive_bayes.html) has some good documentation and [this])(https://dataaspirant.com/2017/02/06/naive-bayes-classifier-machine-learning/) article as well as [this](http://dataaspirant.com/2017/02/20/gaussian-naive-bayes-classifier-implementation-python/) article explain some more.  I also like [this github entry](https://github.com/taneresme/ml.naiveBayes/blob/master/Naive-Bayes-Classifier.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "The Naive Bayes classifier is a straightforward and powerful algorithm for the classification task. When working with a data set with millions of records with some attributes it is suggested to try Naive Bayes because the algorithm is not computationally expensive when compared to other algorithms.  However, Naive Bayes may perform poorly if your training set isn't representative sample of “the real world”.  To understand the naive Bayes classifier we need to understand the Bayes theorem.\n",
    "\n",
    "### What is Bayes Theorem?\n",
    "Bayes theorem named after [Rev. Thomas Bayes](https://en.wikipedia.org/wiki/Thomas_Bayes). It is based on conditional probability, that is, the probability that something will happen, given that something else has already occurred. Using the conditional probability, we can calculate the probability of an event using its prior knowledge.\n",
    "\n",
    "Consider two events, $A$ and $B$. $A \\cap B$ is defined as the intersection of $A$ and $B$.\n",
    "$P(A \\mid B)$ is defined as probability of A given B.\n",
    "\n",
    "![](https://github.com/taneresme/ml.naiveBayes/raw/3a6f361ddab709b6cd9610ef4b9a8146cfccbc82/vennDiagramOfBayesTheorem.png)\n",
    "\n",
    "When Event $B$ has occurred, the sample space is $B$ given on the right in the figure. Now compute the probability of $A$ also occuring (the conditional probability of $A$). That is, find the probability of $A \\cap B$ given that we are in the space of $B$.\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "We can rewrite $P(A \\cap B)$ as $P(A, B)$. These mean the probability of $A$ and $B$ at the same time. So the new form of the equation is:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(A, B)}{P(B)}\n",
    "$$\n",
    "For the probability of $A$ and $B$, we can deduce equations below from the figure above.\n",
    "\n",
    "$$\\begin{align}\n",
    "P(A, B) = P(B, A) = P(A \\mid B)P(B) \\\\\n",
    "P(A, B) = P(B, A) = P(B \\mid A)P(A)\n",
    "\\end{align}$$\n",
    "Let's look at the new form of the equation putting the second form of $P(A, B)$:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B)}\n",
    "$$\n",
    "This equation is known as Bayes Theorem.\n",
    "\n",
    "$P(A \\mid B)$ : the probability of $A$ when $B$ is given\n",
    "$P(B)$ : the marginal probability of $B$\n",
    "$P(B \\mid A)$ : the probability of $B$ when $A$ is given\n",
    "$P(A)$ : the marginal probability of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Methods\n",
    "[Naive Bayes methods](http://scikit-learn.org/stable/modules/naive_bayes.html) are a set of supervised learning algorithms based on applying Bayes theorem with the \"naive\" assumption of independence between every pair of features. Given a class variable $y$ and a dependent feature vector $\\{x_1, ..., x_n\\}$, Bayes theorem states the following relationship:\n",
    "\n",
    "$$\n",
    "P(y \\mid x_1, ..., x_n) = \\frac{P(y) P(x_1, ..., x_n \\mid y)}{P(x_1, ..., x_n)}\n",
    "$$\n",
    "\n",
    "Applying the naive independence assumption that\n",
    "\n",
    "$$\n",
    "P(x_i \\mid y, x_1, ..., x_{i-1}, x_{i+1}, ... x_n) = P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "for all $i$, the relationship is simplified to\n",
    "\n",
    "$$\n",
    "P(y \\mid x_1, ..., x_n) = \\frac{P(y) \\prod_{i=1}^n P(x_i \\mid y)}{P(x_1, ..., x_n)}\n",
    "$$\n",
    "\n",
    "Since $P(x_1, ..., x_n)$ is constant given the input, we can simplify the previous equation to this classification rule:\n",
    "\n",
    "$$\n",
    "P(y \\mid x_1, ..., x_n) \\propto P(y) \\prod_{i=1}^n P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "The [maximum likelihood estimate](https://en.wikipedia.org/wiki/Likelihood_function) is given as\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\\hat{y} = & \\text{arg } \\text{max } P(y) & P(y) \\prod_{i=1}^n P(x_i \\mid y) \\\\ & ^y & \\end{array}\n",
    "$$\n",
    "\n",
    "Use the *Maximum A Posteriori (MAP)* estimation to estimate $P(y)$ and $P(x_i \\mid y)$; the former is then the relative frequency of class y in the training set.\n",
    "\n",
    "[Different naive Bayes classifiers](http://scikit-learn.org/stable/modules/naive_bayes.html) differ mainly by the assumptions they make regarding the distribution of $P(x_i \\mid y)$.\n",
    "\n",
    "In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. For theoretical reasons why naive Bayes works well, and on which types of data it does, see this [reference](http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf).\n",
    "\n",
    "Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What I thought would be interesting is to work though a couple different of packages with [this example](http://dataaspirant.com/2017/02/20/gaussian-naive-bayes-classifier-implementation-python/).  First, we use scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Python Machine learning Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For preprocessing the data\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "# To split the dataset into train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# To model the Gaussian Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# To calculate the accuracy score of the model\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "adult_df=pd.read_csv(url, header = None, delimiter=' *, *', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names.\n",
    "adult_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "                    'marital_status', 'occupation', 'relationship',\n",
    "                    'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "                    'hours_per_week', 'native_country', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(adult_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data cleanup\n",
    "# Is there any missing data?\n",
    "print(adult_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass : 1836\n",
      "education : 0\n",
      "marital_status : 0\n",
      "occupation : 1843\n",
      "relationship : 0\n",
      "race : 0\n",
      "sex : 0\n",
      "native_country : 583\n",
      "income : 0\n"
     ]
    }
   ],
   "source": [
    "# No nulls.  Is there data with \"?\" or other funny stuff going on?\n",
    "for value in ['workclass', 'education',\n",
    "          'marital_status', 'occupation',\n",
    "          'relationship','race', 'sex',\n",
    "          'native_country', 'income']:\n",
    "    print(value,\":\", sum(adult_df[value] == '?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original\n",
    "save_df = adult_df\n",
    "\n",
    "# Get summary statistics - look at all those NaNs\n",
    "sum_stats = adult_df.describe(include= 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing data - e.g., the '?'.  For workclass, we will replace with 'Private' and so forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in ['workclass', 'education',\n",
    "          'marital_status', 'occupation',\n",
    "          'relationship','race', 'sex',\n",
    "          'native_country', 'income']:\n",
    "    adult_df[value] = adult_df[value].replace('?', sum_stats[value][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass : 0\n",
      "education : 0\n",
      "marital_status : 0\n",
      "occupation : 0\n",
      "relationship : 0\n",
      "race : 0\n",
      "sex : 0\n",
      "native_country : 0\n",
      "income : 0\n"
     ]
    }
   ],
   "source": [
    "# Validate...\n",
    "for value in ['workclass', 'education',\n",
    "          'marital_status', 'occupation',\n",
    "          'relationship','race', 'sex',\n",
    "          'native_country', 'income']:\n",
    "    print(value,\":\", sum(adult_df[value] == '?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For naive Bayes, we need to convert all the data values in one format. Encode all the labels with the value between 0 and n_classes-1. To implement this, use LabelEncoder from the scikit learn library. For encoding, we can also use the One-Hot encoder. It encodes the data into binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "workclass_cat = le.fit_transform(save_df.workclass)\n",
    "education_cat = le.fit_transform(save_df.education)\n",
    "marital_cat   = le.fit_transform(save_df.marital_status)\n",
    "occupation_cat = le.fit_transform(save_df.occupation)\n",
    "relationship_cat = le.fit_transform(save_df.relationship)\n",
    "race_cat = le.fit_transform(save_df.race)\n",
    "sex_cat = le.fit_transform(save_df.sex)\n",
    "native_country_cat = le.fit_transform(save_df.native_country)\n",
    "\n",
    "#initialize the encoded categorical columns\n",
    "adult_df['workclass_cat'] = workclass_cat\n",
    "adult_df['education_cat'] = education_cat\n",
    "adult_df['marital_cat'] = marital_cat\n",
    "adult_df['occupation_cat'] = occupation_cat\n",
    "adult_df['relationship_cat'] = relationship_cat\n",
    "adult_df['race_cat'] = race_cat\n",
    "adult_df['sex_cat'] = sex_cat\n",
    "adult_df['native_country_cat'] = native_country_cat\n",
    "\n",
    "#drop the old categorical columns from dataframe\n",
    "dummy_fields = ['workclass', 'education', 'marital_status', \n",
    "                  'occupation', 'relationship', 'race',\n",
    "                  'sex', 'native_country']\n",
    "adult_df = adult_df.drop(dummy_fields, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the adult_df_rev.head()  result below. You will be able to see that all the columns should be reindexed. They are not in proper order.  We want to gather the categorical variables together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_cat</th>\n",
       "      <th>education_cat</th>\n",
       "      <th>marital_cat</th>\n",
       "      <th>occupation_cat</th>\n",
       "      <th>relationship_cat</th>\n",
       "      <th>race_cat</th>\n",
       "      <th>sex_cat</th>\n",
       "      <th>native_country_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "  income  workclass_cat  education_cat  marital_cat  occupation_cat  \\\n",
       "0  <=50K              6              9            4               0   \n",
       "1  <=50K              5              9            2               3   \n",
       "2  <=50K              3             11            0               5   \n",
       "3  <=50K              3              1            2               5   \n",
       "4  <=50K              3              9            2               9   \n",
       "\n",
       "   relationship_cat  race_cat  sex_cat  native_country_cat  \n",
       "0                 1         4        1                  38  \n",
       "1                 0         4        1                  38  \n",
       "2                 1         4        1                  38  \n",
       "3                 0         2        1                  38  \n",
       "4                 5         2        0                   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(adult_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass_cat</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_cat</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_cat</th>\n",
       "      <th>occupation_cat</th>\n",
       "      <th>relationship_cat</th>\n",
       "      <th>race_cat</th>\n",
       "      <th>sex_cat</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country_cat</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass_cat  fnlwgt  education_cat  education_num  marital_cat  \\\n",
       "0   39              6   77516              9             13            4   \n",
       "1   50              5   83311              9             13            2   \n",
       "2   38              3  215646             11              9            0   \n",
       "3   53              3  234721              1              7            2   \n",
       "4   28              3  338409              9             13            2   \n",
       "\n",
       "   occupation_cat  relationship_cat  race_cat  sex_cat  capital_gain  \\\n",
       "0               0                 1         4        1          2174   \n",
       "1               3                 0         4        1             0   \n",
       "2               5                 1         4        1             0   \n",
       "3               5                 0         2        1             0   \n",
       "4               9                 5         2        0             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country_cat income  \n",
       "0             0              40                  38  <=50K  \n",
       "1             0              13                  38  <=50K  \n",
       "2             0              40                  38  <=50K  \n",
       "3             0              40                  38  <=50K  \n",
       "4             0              40                   4  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adult_df = adult_df.reindex_axis(['age', 'workclass_cat', 'fnlwgt', 'education_cat',\n",
    "                                    'education_num', 'marital_cat', 'occupation_cat',\n",
    "                                    'relationship_cat', 'race_cat', 'sex_cat', 'capital_gain',\n",
    "                                    'capital_loss', 'hours_per_week', 'native_country_cat', \n",
    "                                    'income'], axis= 1)\n",
    "\n",
    "display(adult_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization of Data\n",
    "\n",
    "All the data values of our dataframe are numeric. Now, we need to convert them on a single scale. We can standardize the values.  We can use the below formula for standardization.\n",
    "\n",
    "${x}_i = \\frac{{x}_i - mean(x)} {\\sigma(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass_cat</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_cat</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_cat</th>\n",
       "      <th>occupation_cat</th>\n",
       "      <th>relationship_cat</th>\n",
       "      <th>race_cat</th>\n",
       "      <th>sex_cat</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country_cat</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030670</td>\n",
       "      <td>2.624257</td>\n",
       "      <td>-1.063594</td>\n",
       "      <td>-0.335432</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>0.921620</td>\n",
       "      <td>-1.545232</td>\n",
       "      <td>-0.277801</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>0.703061</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.261366</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837096</td>\n",
       "      <td>1.721073</td>\n",
       "      <td>-1.008692</td>\n",
       "      <td>-0.335432</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>-0.406206</td>\n",
       "      <td>-0.790080</td>\n",
       "      <td>-0.900167</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>0.703061</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-2.222119</td>\n",
       "      <td>0.261366</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042641</td>\n",
       "      <td>-0.085295</td>\n",
       "      <td>0.245075</td>\n",
       "      <td>0.181329</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>-1.734032</td>\n",
       "      <td>-0.286645</td>\n",
       "      <td>-0.277801</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>0.703061</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.261366</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057031</td>\n",
       "      <td>-0.085295</td>\n",
       "      <td>0.425795</td>\n",
       "      <td>-2.402474</td>\n",
       "      <td>-1.197440</td>\n",
       "      <td>-0.406206</td>\n",
       "      <td>-0.286645</td>\n",
       "      <td>-0.900167</td>\n",
       "      <td>-1.962591</td>\n",
       "      <td>0.703061</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.261366</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775756</td>\n",
       "      <td>-0.085295</td>\n",
       "      <td>1.408154</td>\n",
       "      <td>-0.335432</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>-0.406206</td>\n",
       "      <td>0.720225</td>\n",
       "      <td>2.211664</td>\n",
       "      <td>-1.962591</td>\n",
       "      <td>-1.422309</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>-5.352858</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass_cat    fnlwgt  education_cat  education_num  \\\n",
       "0  0.030670       2.624257 -1.063594      -0.335432       1.134721   \n",
       "1  0.837096       1.721073 -1.008692      -0.335432       1.134721   \n",
       "2 -0.042641      -0.085295  0.245075       0.181329      -0.420053   \n",
       "3  1.057031      -0.085295  0.425795      -2.402474      -1.197440   \n",
       "4 -0.775756      -0.085295  1.408154      -0.335432       1.134721   \n",
       "\n",
       "   marital_cat  occupation_cat  relationship_cat  race_cat   sex_cat  \\\n",
       "0     0.921620       -1.545232         -0.277801  0.393661  0.703061   \n",
       "1    -0.406206       -0.790080         -0.900167  0.393661  0.703061   \n",
       "2    -1.734032       -0.286645         -0.277801  0.393661  0.703061   \n",
       "3    -0.406206       -0.286645         -0.900167 -1.962591  0.703061   \n",
       "4    -0.406206        0.720225          2.211664 -1.962591 -1.422309   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country_cat income  \n",
       "0      0.148451     -0.216656       -0.035429            0.261366  <=50K  \n",
       "1     -0.145918     -0.216656       -2.222119            0.261366  <=50K  \n",
       "2     -0.145918     -0.216656       -0.035429            0.261366  <=50K  \n",
       "3     -0.145918     -0.216656       -0.035429            0.261366  <=50K  \n",
       "4     -0.145918     -0.216656       -0.035429           -5.352858  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = ['age', 'workclass_cat', 'fnlwgt', 'education_cat', 'education_num',\n",
    "                'marital_cat', 'occupation_cat', 'relationship_cat', 'race_cat',\n",
    "                'sex_cat', 'capital_gain', 'capital_loss', 'hours_per_week',\n",
    "                'native_country_cat']\n",
    "\n",
    "scaled_features = {}\n",
    "for each in num_features:\n",
    "    mean, std = adult_df[each].mean(), adult_df[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    adult_df.loc[:, each] = (adult_df[each] - mean)/std\n",
    "\n",
    "display(adult_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Sets\n",
    "\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = adult_df.values[:,:14]\n",
    "target = adult_df.values[:,14]\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                            target, test_size = 0.33, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03067008638002341, 2.6242573354416034, -1.0635944124434624,\n",
       "        ..., -0.2166562000280046, -0.03542890292132261,\n",
       "        0.2613659753386185],\n",
       "       [0.8370961257882877, 1.7210732167696725, -1.0086915112165729, ...,\n",
       "        -0.2166562000280046, -2.2221189981594556, 0.2613659753386185],\n",
       "       [-0.04264137174800061, -0.08529502057418954, 0.24507474139091864,\n",
       "        ..., -0.2166562000280046, -0.03542890292132261,\n",
       "        0.2613659753386185],\n",
       "       ...,\n",
       "       [1.4235877908124799, -0.08529502057418954, -0.3587719044411823,\n",
       "        ..., -0.2166562000280046, -0.03542890292132261,\n",
       "        0.2613659753386185],\n",
       "       [-1.215624701796385, -0.08529502057418954, 0.11095818060267934,\n",
       "        ..., -0.2166562000280046, -1.6551993438384582,\n",
       "        0.2613659753386185],\n",
       "       [0.9837190420443357, 0.8178890980977415, 0.9298782967974407, ...,\n",
       "        -0.2166562000280046, -0.03542890292132261, 0.2613659753386185]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '<=50K', '<=50K', ..., '<=50K', '<=50K', '>50K'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "We are using Scikit-Learn and have built a GaussianNB classifier. The classifier is trained using training data. We can use fit() method for training it. After building a classifier, our model is ready to make predictions. We can use predict() method with test set features as its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes process time = 0.13645672798156738\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, target_train)\n",
    "target_pred = clf.predict(features_test)\n",
    "print(\"Naive Bayes process time = {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of our Gaussian Naive Bayes model\n",
    "It’s time to test the quality of our model. We have made some predictions. Let’s compare the model’s prediction with actual target values for the test set. By following this method, we are going to calculate the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014144798064397"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn gives an accuracy of 80% in predicting salaries with Naive Bayes.\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "\n",
    "Let's try the Bernoulli Naive Bayes method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes process time = 0.19118714332580566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.802252000744463"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "start_time = time.time()\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(features_train, target_train)\n",
    "target_pred = bnb.predict(features_test)\n",
    "print(\"Bernoulli Naive Bayes process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is hardly an improvement.\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "[Decision trees](http://scikit-learn.org/stable/modules/tree.html) are another option for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree process time = 0.3126842975616455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8126744835287549"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "start_time = time.time()\n",
    "tclf = tree.DecisionTreeClassifier()\n",
    "tclf = tclf.fit(features_train, target_train)\n",
    "target_pred = tclf.predict(features_test)\n",
    "print(\"Decision Tree process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "We've gone this far - let's try a [Random Forest)](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest process time = 0.2171158790588379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.794714312302252"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "rfclf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfclf.fit(features_train, target_train)\n",
    "target_pred = rfclf.predict(features_test)\n",
    "print(\"Random Forest process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was unexpected.  Previously, I was under the impression that Random Forests are one of the best classifiers.  But that is a blanket statement that shouldn't be made in general.  Indeed, some methods will do better than others on different problems.\n",
    "\n",
    "Or perhaps, we should just increase the depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest process time = 0.28003907203674316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8401265587195236"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rfclf = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "rfclf.fit(features_train, target_train)\n",
    "target_pred = rfclf.predict(features_test)\n",
    "print(\"Random Forest process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try once more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest process time = 0.34059715270996094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.854178298901917"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rfclf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "rfclf.fit(features_train, target_train)\n",
    "target_pred = rfclf.predict(features_test)\n",
    "print(\"Random Forest process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did suspect that increasing the depth would only so far.\n",
    "\n",
    "# AdaBoost\n",
    "\n",
    "Let's try boosting with [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) and see what that does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost process time = 13.648805856704712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8542713567839196"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "adaclf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "adaclf.fit(features_train, target_train)\n",
    "target_pred = adaclf.predict(features_test)\n",
    "print(\"AdaBoost process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but very slow.  And in reality, not that great of an improvement over Naive Bayes.  Out of curiosity, let's increase depth and estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost process time = 14.740965127944946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8652521868602271"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "adaclf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=200)\n",
    "adaclf.fit(features_train, target_train)\n",
    "target_pred = adaclf.predict(features_test)\n",
    "print(\"AdaBoost process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The claim was that SAMME.R [converges faster](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) and has smaller test error.  We did get an improvement.  I didn't see faster converges - still seemed slow.  One more variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost process time = 38.720948457717896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8597617718220734"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "adaclf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=400)\n",
    "adaclf.fit(features_train, target_train)\n",
    "target_pred = adaclf.predict(features_test)\n",
    "print(\"AdaBoost process time = {}\".format(time.time()-start_time))\n",
    "\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
